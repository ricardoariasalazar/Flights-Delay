{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Producer\n",
    "The following code reads the data given, and transform it into a format that is readable by `Kafka`, that is why is transformed from csv to list of dictionaries. This information is going to be sent to a topic called `flightTopic` and we are going to divided in a way that each batch have a random number of records using two different timestamps.\n",
    "\n",
    "In order to use the ML pipeline in the streaming application, we need to wrangle the data deleting all the NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing records..\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "import random\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def read_csv(path):\n",
    "    '''Read the CSV file flights*.csv'''\n",
    "    columns_to_drop = ['CANCELLATION_REASON', 'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY']\n",
    "    df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', path))))\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def publish_message(producer_instance, topic_name, data):\n",
    "    try:\n",
    "        producer_instance.send(topic_name, data)\n",
    "        #print(data)\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                                  value_serializer=lambda x: dumps(x).encode('ascii'),\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer\n",
    "    \n",
    "def getFlightRecords(df, keys):\n",
    "    \"\"\"\n",
    "    Convert a dataframe into a list of lists, where each list is a collection of dictionaries, \n",
    "    that store the data of the flights that share the same key (DAY_OF_WEEK). Do not include any NA value\n",
    "    So we can avoid troubles in the future\n",
    "    \"\"\"\n",
    "    flightRecords = [df[df.DAY_OF_WEEK == i].to_dict('records') for i in keys]\n",
    "    return flightRecords\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    topic = 'flight_Topic'\n",
    "    print('Publishing records..')\n",
    "    flightProducer = connect_kafka_producer()\n",
    "    \n",
    "    \n",
    "    keyFlights = list(range(1,8)) # List of all possible keys\n",
    "    \n",
    "    flights = read_csv('./flight-delays/flight1.csv') # Read the CSV file\n",
    "    \n",
    "    flightRecords = getFlightRecords(flights, keyFlights) # Convert the pandas dataframe into a list of lists by key\n",
    "    \n",
    "    start_index=0 # Set start index as 0 (the first element of the list)\n",
    "    temp_Y = [] # Define temp_Y as the previous value of Y, it starts as an empty list\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        X = [] # Define the batch X as empty list\n",
    "        Y = [] # Define the batch Y as empty list\n",
    "        \n",
    "        for key in keyFlights: # For each key in keyFlights\n",
    "            \n",
    "            ts = {'ts': int(dt.datetime.now().timestamp())}  #define the current timestamp\n",
    "            \n",
    "            A = random.randrange(70,101) #define the size of the sub-batch A \n",
    "            B = random.randrange(5,11) #define the size of the sub-batch B \n",
    "            \n",
    "            # Define the range of the sub-batchs of each key, each sub-batch is not overlapped\n",
    "            min_index_A, max_index_A = start_index, start_index+A # Define the range of rows of sub-batch A\n",
    "            min_index_B, max_index_B = start_index+A, start_index+A+B # Define the range of rows of sub-batch B\n",
    "            \n",
    "            start_index += A+B # Set a new start_index to make sure we do not repeat records to be streamed\n",
    "            \n",
    "            subbatch_Ai = flightRecords[key - 1][min_index_A:max_index_A] # Get the rows that belong to sub-batch Ai\n",
    "            \n",
    "            # Add the current time stamp to every record of the sub-batch Ai\n",
    "            for i in range(len(subbatch_Ai)): \n",
    "                subbatch_Ai[i] = dict(**ts, **subbatch_Ai[i])\n",
    "                        \n",
    "            subbatch_Bi = flightRecords[key - 1][min_index_B:max_index_B] # Get the rows that belong to sub-batch Bi\n",
    "            \n",
    "            # Add the current time stamp to every record of the sub-batch Bi\n",
    "            for i in range(len(subbatch_Bi)):\n",
    "                subbatch_Bi[i] = dict(**ts, **subbatch_Bi[i])\n",
    "            \n",
    "            X += subbatch_Ai # Create batch X composed by all the Ai concatenated\n",
    "            Y += subbatch_Bi # Create batch Y composed by all the Bi concatenated\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(temp_Y) == 0: # If it is time_0 and there is not temp_Y\n",
    "            data = X  # send just batch X\n",
    "        else:\n",
    "            data = X + temp_Y # Send batch Xi and Yi-1\n",
    "            \n",
    "        temp_Y = Y # Create temp_Y or Yi-1 based on the current value of Y\n",
    "     \n",
    "        publish_message(flightProducer, topic, data)\n",
    "        \n",
    "        #reset to start from begining\n",
    "        if(start_index>=len(flightRecords)):\n",
    "            start_index=0\n",
    "            \n",
    "        sleep(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
